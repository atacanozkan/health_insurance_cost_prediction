{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlowBootamp1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgqXqgZ/Y3UxCeJX2B2t5e"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Pandas, Numpy, Seaborn, Matplotlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import Label Encoder and train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import Label Encoder and train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load dataset\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/atacanozkan/health_insurance_cost_prediction/main/insurance.csv\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "OgKlbGyLg5Zh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "aef98b05-9d6b-41f5-f63c-c8a5ad06173e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-348097c6-067c-4ba0-96a3-4d89db8e7c05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-348097c6-067c-4ba0-96a3-4d89db8e7c05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-348097c6-067c-4ba0-96a3-4d89db8e7c05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-348097c6-067c-4ba0-96a3-4d89db8e7c05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sklearn\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "pd.set_option('display.width', 170)\n",
        "\n",
        "def load_dataset(filename, extension='.csv'):\n",
        "    \"\"\"\n",
        "    Iports the dataset\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "    \"\"\"\n",
        "    if 'csv' in extension:\n",
        "        data = pd.read_csv(filename+extension)\n",
        "    elif 'xls' in extension:\n",
        "        data = pd.read_excel(filename+extension)\n",
        "    elif 'pkl' in extension:\n",
        "        data = pd.DataFrame(pickle.load(open(filename+extension, 'rb')))\n",
        "    return data\n",
        "# df = load_dataset(\"insurance\")\n",
        "\n",
        "######################################################\n",
        "# Exploratory Data Analysis\n",
        "######################################################\n",
        "\n",
        "# Tablonun özet istatistikleri:\n",
        "def check_df(dataframe, head=5):\n",
        "    \"\"\"\n",
        "    Prints out the shape, types, head, missing values and quantiles of the dataframe\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe\n",
        "    head\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    No return\n",
        "    \"\"\"\n",
        "    print(\"##################### Shape #####################\")\n",
        "    print(dataframe.shape)\n",
        "    print(\"##################### Types #####################\")\n",
        "    print(dataframe.dtypes)\n",
        "    print(\"##################### Head #####################\")\n",
        "    print(dataframe.head(head))\n",
        "    print(\"##################### Tail #####################\")\n",
        "    print(dataframe.tail(head))\n",
        "    print(\"################ Missing Values ################\")\n",
        "    print(dataframe.isnull().sum())\n",
        "check_df(df, 5)\n",
        "df.describe()\n",
        "\n",
        "# Kategorik ve sayısal değişkenlerin belirlenmesi\n",
        "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
        "    \"\"\"\n",
        "    Determines the categorical, numerical and categorical but cardinal columns.\n",
        "\n",
        "    Parameters\n",
        "    ------\n",
        "        dataframe: dataframe\n",
        "                dataframe whihc inludes the columns\n",
        "        cat_th: int, optional\n",
        "                class threshold valuse for determining numeric but categorical variable\n",
        "        car_th: int, optional\n",
        "                class threshold valuse for determining categoric but cardinal variable\n",
        "\n",
        "    Returns\n",
        "    ------\n",
        "        cat_cols: list\n",
        "                categorical columns\n",
        "        num_cols: list\n",
        "                numerical columns\n",
        "        cat_but_car: list\n",
        "                categoric but cardinal columns\n",
        "\n",
        "    Examples\n",
        "    ------\n",
        "        import seaborn as sns\n",
        "        df = sns.load_dataset(\"iris\")\n",
        "        print(grab_col_names(df))\n",
        "\n",
        "\n",
        "    Notes\n",
        "    ------\n",
        "        cat_cols + num_cols + cat_but_car = total columns\n",
        "        cat_cols = all_cat_cols + num_but_cat - cat_but_car\n",
        "        num_cols = all_num_cols - num_but_cat\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Observations: {dataframe.shape[0]}\")\n",
        "    print(f\"Variables: {dataframe.shape[1]}\")\n",
        "\n",
        "    # cat cols\n",
        "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
        "    print(f'init cat_cols: {len(cat_cols)}')\n",
        "\n",
        "    # num cols\n",
        "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
        "    print(f'init num_cols: {len(num_cols)}')\n",
        "\n",
        "    # num but cat cols\n",
        "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
        "                   dataframe[col].dtypes != \"O\"]\n",
        "    print(f'num_but_cat: {len(num_but_cat)}')\n",
        "\n",
        "    # cat but car cols\n",
        "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
        "                   dataframe[col].dtypes == \"O\"]\n",
        "    print(f'cat_but_car: {len(cat_but_car)}')\n",
        "\n",
        "    # cat cols\n",
        "    cat_cols = cat_cols + num_but_cat\n",
        "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
        "    print(f'final cat_cols: {len(cat_cols)}')\n",
        "\n",
        "    # num_cols\n",
        "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
        "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
        "    print(f'final num_cols: {len(num_cols)}')\n",
        "\n",
        "    return cat_cols, num_cols, cat_but_car\n",
        "cat_cols, num_cols, cat_but_car = grab_col_names(df)\n",
        "\n",
        "######################################################\n",
        "# Feature Engineering\n",
        "######################################################\n",
        "def new_feature_interval(dataframe, col, interval_value, header=\"new\"):\n",
        "    if header == \"new\":\n",
        "        new_col = \"new_\" + col\n",
        "    else:\n",
        "        new_col = header\n",
        "    for intrvl, val in interval_value.items():\n",
        "        dataframe.loc[[var in intrvl for var in dataframe[col]], new_col] = val\n",
        "new_feature_interval(df, 'age',\n",
        "                   {\n",
        "                    pd.Interval(-np.inf, 18, closed='neither'):'young',\n",
        "                    pd.Interval(18, 44, closed='left'):'mature',\n",
        "                    pd.Interval(44, 64, closed='left'):'senior',\n",
        "                    pd.Interval(64, np.inf, closed='left'):'old'\n",
        "                   }\n",
        "                   )\n",
        "\n",
        "# Tablonun özet istatistikleri:\n",
        "check_df(df)      \n",
        "\n",
        "##########################\n",
        "# Görsel Analiz\n",
        "##########################\n",
        "def plot_numerical_col(dataframe, numerical_col):\n",
        "    dataframe[numerical_col].hist(bins=20)\n",
        "    plt.xlabel(numerical_col)\n",
        "    plt.show()\n",
        "for col in num_cols:\n",
        "    plot_numerical_col(df, col)\n",
        "\n",
        "def plot_bar(df, x, y, title, save=None):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    sns.set(font_scale=1)\n",
        "    sns.barplot(x=x, y=y, data=df)\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    if save != None:\n",
        "        plt.savefig(save)\n",
        "\n",
        "for col in cat_cols:\n",
        "    plot_bar(df, col, 'charges', col)\n",
        "\n",
        "plot_bar(df, 'smoker', 'bmi', col)\n",
        "plot_bar(df, 'region', 'bmi', col)\n",
        "sns.boxplot(x='new_age',y='bmi',data=df)\n",
        "\n",
        "\n",
        "##########################\n",
        "# Target Analizi\n",
        "##########################\n",
        "\n",
        "# Tüm kategorik değişkenlerin özet istatistikleri:\n",
        "def cat_cols_summary(dataframe, cat_cols, plot=False):\n",
        "    \"\"\"\n",
        "    Ratio of the categorical classes in a column\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe\n",
        "    col_name\n",
        "    plot\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    No return\n",
        "    \"\"\"\n",
        "    print(\"############## Frequency and Ratio #############\")\n",
        "    print(pd.DataFrame({\"Freq\": dataframe[cat_cols].value_counts(),\n",
        "                        \"Ratio\": 100 * dataframe[cat_cols].value_counts() / len(dataframe)}).rename_axis(cat_cols))\n",
        "\n",
        "    if plot:\n",
        "        for col in cat_cols:\n",
        "            sns.countplot(x=dataframe[col], data=dataframe)\n",
        "            plt.show()\n",
        "cat_cols_summary(df, 'charges')\n",
        "\n",
        "##########################\n",
        "# Feature Analizi\n",
        "##########################\n",
        "\n",
        "# Tüm sayısal değişkenlerin özet istatistikleri:\n",
        "def num_cols_summary(dataframe, num_cols, plot=False):\n",
        "    \"\"\"\n",
        "    Numerical variable exploration\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe\n",
        "    numerical_col\n",
        "    plot\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    No return\n",
        "    \"\"\"\n",
        "    print(\"################### Describe ###################\")\n",
        "    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40,\n",
        "                 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n",
        "    print(dataframe[num_cols].describe(quantiles).T)\n",
        "\n",
        "    if plot:\n",
        "        for col in num_cols:\n",
        "            dataframe[col].hist(bins=20)\n",
        "            plt.xlabel(col)\n",
        "            plt.title(col)\n",
        "            plt.show()\n",
        "num_cols_summary(df, num_cols, False)\n",
        "\n",
        "##########################\n",
        "# Target vs Features Analizi\n",
        "##########################\n",
        "\n",
        "def target_vs_num_cols_summary(dataframe, target, num_col):\n",
        "    \"\"\"\n",
        "    Prints out the defined numeric variable mean of the target classes\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe\n",
        "    target\n",
        "    num_col\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    No return\n",
        "    \"\"\"\n",
        "    print(pd.DataFrame(\n",
        "        {num_col+\"_MEAN\": dataframe.groupby(target).agg({num_col: \"mean\"})[num_col]}), end=\"\\n\\n\\n\")\n",
        "for col in num_cols:\n",
        "    target_vs_num_cols_summary(df, \"charges\", col)\n",
        "\n",
        "######################################################\n",
        "# Data Preprocessing (Veri Ön İşleme)\n",
        "######################################################\n",
        "\n",
        "# Eksik değer incelemesi:\n",
        "df.isnull().sum()\n",
        "\n",
        "# Aykırı değer incelemesi:\n",
        "def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):\n",
        "    \"\"\"\n",
        "    Appoints the lower and upper thresholds by use of quantile\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe\n",
        "    col_name\n",
        "    q1: first quantile percentage\n",
        "    q3: third quantile percentage\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    low_limit and up_limit thresholds as tupple\n",
        "    \"\"\"\n",
        "    quartile1 = dataframe[col_name].quantile(q1)\n",
        "    quartile3 = dataframe[col_name].quantile(q3)\n",
        "    interquantile_range = quartile3 - quartile1\n",
        "    up_limit = quartile3 + 1.5 * interquantile_range\n",
        "    low_limit = quartile1 - 1.5 * interquantile_range\n",
        "    return low_limit, up_limit\n",
        "def check_outlier(dataframe, col_name, q1=0.05, q3=0.95):\n",
        "    \"\"\"\n",
        "    Checks if there is an outlier and return bool value\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe\n",
        "    col_name\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    outlier existance as bool\n",
        "    \"\"\"\n",
        "    low_limit, up_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n",
        "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "for col in num_cols:\n",
        "    print(col, check_outlier(df, col))\n",
        "\n",
        "\n",
        "#############################################\n",
        "# One-Hot Encoding\n",
        "#############################################\n",
        "def one_hot_encoder(dataframe, cat_cols, drop_first=False, dummy_na=False):\n",
        "    \"\"\"\n",
        "    Encodes the column of the dataframe with binary labels\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe\n",
        "    categorical_cols\n",
        "    drop_first\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    The one-hot encoded columns added dataframe\n",
        "    \"\"\"\n",
        "    dataframe = pd.get_dummies(\n",
        "        dataframe, columns=cat_cols, drop_first=drop_first, dummy_na=dummy_na)\n",
        "    return dataframe\n",
        "df = one_hot_encoder(df, cat_cols)\n",
        "\n",
        "# Tablonun özet istatistikleri:\n",
        "check_df(df)\n",
        "\n",
        "\n",
        "\n",
        "#############################################\n",
        "# Feature Scaling (Özellik Ölçeklendirme)\n",
        "#############################################\n",
        "def robust_scaling(dataframe, col_name):\n",
        "    \"\"\"\n",
        "    Scale features using statistics that are robust to outliers.\n",
        "    This Scaler removes the median and scales the data according to the quantile range (defaults to IQR)\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe\n",
        "    col_name\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Robust scaled dataframe\n",
        "    \"\"\"\n",
        "    rs = RobustScaler()\n",
        "    dataframe[col_name] = rs.fit_transform(dataframe[[col_name]])\n",
        "    return dataframe\n",
        "for col in num_cols:\n",
        "    df[col] = robust_scaling(df, col)\n",
        "\n",
        "df.head()\n",
        "\n",
        "def save_dataset(data, filename, extension='.csv'):\n",
        "    \"\"\"\n",
        "    Iports the dataset\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "    \"\"\"\n",
        "    if 'csv' in extension:\n",
        "        data.to_csv(filename+extension)\n",
        "    elif 'xls' in extension:\n",
        "        data.to_excel(filename+extension, index=False)\n",
        "    elif 'pkl' in extension:\n",
        "        pickle.dump(data, open(filename+extension, 'wb'))\n",
        "# save_dataset(df, 'insurance_data_prep', '.pkl')"
      ],
      "metadata": {
        "id": "jJ2AH_C5LyOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g51rM6EzLx_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# Hitters\n",
        "#######################################\n",
        "\n",
        "# !pip install xgboost\n",
        "# !pip install lightgbm\n",
        "# conda install -c conda-forge lightgbm\n",
        "# !pip install catboost\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate\n",
        "\n",
        "from helpers.data_preparation import *\n",
        "from helpers.exploratory_data_analysis import *\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"datasets/hitters.csv\")\n",
        "df.head()\n",
        "\n",
        "#######################################\n",
        "# Quick Data Preprocessing\n",
        "#######################################\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "cat_cols, num_cols, cat_but_car = grab_col_names(df)\n",
        "\n",
        "for col in cat_cols:\n",
        "    cat_summary(df, col)\n",
        "\n",
        "for col in cat_cols:\n",
        "    df.loc[:, col] = label_encoder(df, col)\n",
        "\n",
        "check_df(df)\n",
        "\n",
        "y = df[\"Salary\"]\n",
        "X = df.drop([\"Salary\"], axis=1)\n",
        "\n",
        "######################################################\n",
        "# Base Models\n",
        "######################################################\n",
        "\n",
        "models = [('LR', LinearRegression()),\n",
        "          (\"Ridge\", Ridge()),\n",
        "          (\"Lasso\", Lasso()),\n",
        "          (\"ElasticNet\", ElasticNet()),\n",
        "          ('KNN', KNeighborsRegressor()),\n",
        "          ('CART', DecisionTreeRegressor()),\n",
        "          ('RF', RandomForestRegressor()),\n",
        "          ('SVR', SVR()),\n",
        "          ('GBM', GradientBoostingRegressor()),\n",
        "          (\"XGBoost\", XGBRegressor(objective='reg:squarederror')),\n",
        "          (\"LightGBM\", LGBMRegressor()),\n",
        "          # (\"CatBoost\", CatBoostRegressor(verbose=False))\n",
        "          ]\n",
        "\n",
        "for name, regressor in models:\n",
        "    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n",
        "    print(f\"RMSE: {round(rmse, 4)} ({name}) \")\n",
        "\n",
        "\n",
        "######################################################\n",
        "# Automated Hyperparameter Optimization\n",
        "######################################################\n",
        "\n",
        "\n",
        "cart_params = {'max_depth': range(1, 20),\n",
        "               \"min_samples_split\": range(2, 30)}\n",
        "\n",
        "rf_params = {\"max_depth\": [5, 8, 15, None],\n",
        "             \"max_features\": [5, 7, \"auto\"],\n",
        "             \"min_samples_split\": [8, 15, 20],\n",
        "             \"n_estimators\": [200, 500, 1000]}\n",
        "\n",
        "xgboost_params = {\"learning_rate\": [0.1, 0.01, 0.01],\n",
        "                  \"max_depth\": [5, 8, 12, 20],\n",
        "                  \"n_estimators\": [100, 200, 300, 500],\n",
        "                  \"colsample_bytree\": [0.5, 0.8, 1]}\n",
        "\n",
        "lightgbm_params = {\"learning_rate\": [0.01, 0.1, 0.001],\n",
        "                   \"n_estimators\": [300, 500, 1500],\n",
        "                   \"colsample_bytree\": [0.5, 0.7, 1]}\n",
        "\n",
        "regressors = [(\"CART\", DecisionTreeRegressor(), cart_params),\n",
        "              (\"RF\", RandomForestRegressor(), rf_params),\n",
        "              ('XGBoost', XGBRegressor(objective='reg:squarederror'), xgboost_params),\n",
        "              ('LightGBM', LGBMRegressor(), lightgbm_params)]\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "for name, regressor, params in regressors:\n",
        "    print(f\"########## {name} ##########\")\n",
        "    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n",
        "    print(f\"RMSE: {round(rmse, 4)} ({name}) \")\n",
        "\n",
        "    gs_best = GridSearchCV(regressor, params, cv=3, n_jobs=-1, verbose=False).fit(X, y)\n",
        "\n",
        "    final_model = regressor.set_params(**gs_best.best_params_)\n",
        "    rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n",
        "    print(f\"RMSE (After): {round(rmse, 4)} ({name}) \")\n",
        "\n",
        "    print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n",
        "\n",
        "    best_models[name] = final_model\n",
        "\n",
        "\n",
        "######################################################\n",
        "# # Stacking & Ensemble Learning\n",
        "######################################################\n",
        "\n",
        "voting_reg = VotingRegressor(estimators=[('RF', best_models[\"RF\"]),\n",
        "                                         ('LightGBM', best_models[\"LightGBM\"])])\n",
        "\n",
        "voting_reg.fit(X, y)\n",
        "\n",
        "\n",
        "np.mean(np.sqrt(-cross_val_score(voting_reg, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n",
        "\n",
        "######################################################\n",
        "# Prediction for a New Observation\n",
        "######################################################\n",
        "\n",
        "X.columns\n",
        "random_user = X.sample(1, random_state=45)\n",
        "voting_reg.predict(random_user)\n"
      ],
      "metadata": {
        "id": "Vfh9miUNxyaJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}