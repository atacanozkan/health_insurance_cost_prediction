{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlowBootamp1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqoFcZX8kMKJas/7dH093+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Pandas, Numpy, Seaborn, Matplotlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import Label Encoder and train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import Label Encoder and train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "df = pd.read_csv('./insurance.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "OgKlbGyLg5Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJ2AH_C5LyOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g51rM6EzLx_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# Hitters\n",
        "#######################################\n",
        "\n",
        "# !pip install xgboost\n",
        "# !pip install lightgbm\n",
        "# conda install -c conda-forge lightgbm\n",
        "# !pip install catboost\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate\n",
        "\n",
        "from helpers.data_preparation import *\n",
        "from helpers.exploratory_data_analysis import *\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"datasets/hitters.csv\")\n",
        "df.head()\n",
        "\n",
        "#######################################\n",
        "# Quick Data Preprocessing\n",
        "#######################################\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "cat_cols, num_cols, cat_but_car = grab_col_names(df)\n",
        "\n",
        "for col in cat_cols:\n",
        "    cat_summary(df, col)\n",
        "\n",
        "for col in cat_cols:\n",
        "    df.loc[:, col] = label_encoder(df, col)\n",
        "\n",
        "check_df(df)\n",
        "\n",
        "y = df[\"Salary\"]\n",
        "X = df.drop([\"Salary\"], axis=1)\n",
        "\n",
        "######################################################\n",
        "# Base Models\n",
        "######################################################\n",
        "\n",
        "models = [('LR', LinearRegression()),\n",
        "          (\"Ridge\", Ridge()),\n",
        "          (\"Lasso\", Lasso()),\n",
        "          (\"ElasticNet\", ElasticNet()),\n",
        "          ('KNN', KNeighborsRegressor()),\n",
        "          ('CART', DecisionTreeRegressor()),\n",
        "          ('RF', RandomForestRegressor()),\n",
        "          ('SVR', SVR()),\n",
        "          ('GBM', GradientBoostingRegressor()),\n",
        "          (\"XGBoost\", XGBRegressor(objective='reg:squarederror')),\n",
        "          (\"LightGBM\", LGBMRegressor()),\n",
        "          # (\"CatBoost\", CatBoostRegressor(verbose=False))\n",
        "          ]\n",
        "\n",
        "for name, regressor in models:\n",
        "    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n",
        "    print(f\"RMSE: {round(rmse, 4)} ({name}) \")\n",
        "\n",
        "\n",
        "######################################################\n",
        "# Automated Hyperparameter Optimization\n",
        "######################################################\n",
        "\n",
        "\n",
        "cart_params = {'max_depth': range(1, 20),\n",
        "               \"min_samples_split\": range(2, 30)}\n",
        "\n",
        "rf_params = {\"max_depth\": [5, 8, 15, None],\n",
        "             \"max_features\": [5, 7, \"auto\"],\n",
        "             \"min_samples_split\": [8, 15, 20],\n",
        "             \"n_estimators\": [200, 500, 1000]}\n",
        "\n",
        "xgboost_params = {\"learning_rate\": [0.1, 0.01, 0.01],\n",
        "                  \"max_depth\": [5, 8, 12, 20],\n",
        "                  \"n_estimators\": [100, 200, 300, 500],\n",
        "                  \"colsample_bytree\": [0.5, 0.8, 1]}\n",
        "\n",
        "lightgbm_params = {\"learning_rate\": [0.01, 0.1, 0.001],\n",
        "                   \"n_estimators\": [300, 500, 1500],\n",
        "                   \"colsample_bytree\": [0.5, 0.7, 1]}\n",
        "\n",
        "regressors = [(\"CART\", DecisionTreeRegressor(), cart_params),\n",
        "              (\"RF\", RandomForestRegressor(), rf_params),\n",
        "              ('XGBoost', XGBRegressor(objective='reg:squarederror'), xgboost_params),\n",
        "              ('LightGBM', LGBMRegressor(), lightgbm_params)]\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "for name, regressor, params in regressors:\n",
        "    print(f\"########## {name} ##########\")\n",
        "    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n",
        "    print(f\"RMSE: {round(rmse, 4)} ({name}) \")\n",
        "\n",
        "    gs_best = GridSearchCV(regressor, params, cv=3, n_jobs=-1, verbose=False).fit(X, y)\n",
        "\n",
        "    final_model = regressor.set_params(**gs_best.best_params_)\n",
        "    rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n",
        "    print(f\"RMSE (After): {round(rmse, 4)} ({name}) \")\n",
        "\n",
        "    print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n",
        "\n",
        "    best_models[name] = final_model\n",
        "\n",
        "\n",
        "######################################################\n",
        "# # Stacking & Ensemble Learning\n",
        "######################################################\n",
        "\n",
        "voting_reg = VotingRegressor(estimators=[('RF', best_models[\"RF\"]),\n",
        "                                         ('LightGBM', best_models[\"LightGBM\"])])\n",
        "\n",
        "voting_reg.fit(X, y)\n",
        "\n",
        "\n",
        "np.mean(np.sqrt(-cross_val_score(voting_reg, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n",
        "\n",
        "######################################################\n",
        "# Prediction for a New Observation\n",
        "######################################################\n",
        "\n",
        "X.columns\n",
        "random_user = X.sample(1, random_state=45)\n",
        "voting_reg.predict(random_user)\n"
      ],
      "metadata": {
        "id": "Vfh9miUNxyaJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}